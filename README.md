# SReLU-PyTorch
SReLU ([S-shaped Rectified Linear Unit](arxiv.org/abs/1512.07030)) implementation in PyTorch. 

It's the simplest implementation possible, and you just need to copy and paste. Thresholds and slopes are learnable parameters.

More information: https://paperswithcode.com/method/srelu
